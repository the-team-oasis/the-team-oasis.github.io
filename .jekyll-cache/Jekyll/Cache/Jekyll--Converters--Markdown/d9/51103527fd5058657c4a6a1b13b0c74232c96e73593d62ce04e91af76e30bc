I"İ<p><img src="/assets/img/infrastructure/shared-blockvolume/SCR-20220823-k0g.png" alt="" /></p>

<h3 id="shared-blockvolume">Shared Blockvolume</h3>
<p>OCI(Oracle Cloud Infrastructure)ëŠ” ì—¬ëŸ¬ Compute ì¸ìŠ¤í„´ìŠ¤ê°€ ê³µìœ í•˜ëŠ” Block Volumeì„ ì§€ì›í•©ë‹ˆë‹¤. 1ê°œì˜ Block Volumeì„ 2ê°œ ì´ ì´ìƒì˜ Compute ì¸ìŠ¤í„´ìŠ¤ê°€ ë§ˆìš´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ Compute ì¸ìŠ¤í„´ìŠ¤ê°€ 1ê°œ Block Volumeì„ ì½ê¸°/ì“°ê¸° ëª¨ë“œë¡œ ë§ˆìš´íŠ¸í•  ê²½ìš°, ì“°ê¸° ì¤‘ë³µì„ ë°©ì§€í•˜ê¸° ìœ„í•´ì„œ ì—¬ëŸ¬ Compute ì¸ìŠ¤í„´ìŠ¤ì˜ íŒŒì¼ ì“°ê¸°ë¥¼ ì¡°ì •í•˜ëŠ” ì¤‘ì¬ ì†Œí”„íŠ¸ì›¨ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ëŸ° ì¤‘ì¬ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ Clusterwareë¼ê³  í•©ë‹ˆë‹¤.</p>

<p>OCIëŠ” ê³µìœ  ë³¼ë¥¨ì€ë‹¤ìŒê³¼ ê°™ì€ 3ê°œ Clusterwareë¥¼ ì§€ì›í•©ë‹ˆë‹¤.</p>

<ul>
  <li>OCSF2(Oracle Cluster File System Version 2)</li>
  <li>GlusterFS</li>
  <li>IBM Spectrum Scale</li>
</ul>

<blockquote>
  <p>ì œì•½ì‚¬í•­
<img src="/assets/img/infrastructure/shared-blockvolume/7.png" alt="" /></p>
</blockquote>

<p><img src="/assets/img/infrastructure/shared-blockvolume/1.png" alt="" /></p>

<p>ë¸”ë¡ë³¼ë¥¨ì„ ìƒì„±í•©ë‹ˆë‹¤.
<img src="/assets/img/infrastructure/shared-blockvolume/2.png" alt="" /></p>

<p>Compute ë‚´ shared blockstorage ì„¤ì • ë° iSCSI ì •ë³´ í™•ì¸</p>
<ul>
  <li>ìœ„ ì•ì—ì„œ ìƒì„±ëœ computeì˜ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ ìœ„í•´ì„œ ì•„ë˜ compute ë¥¼ í´ë¦­í•©ë‹ˆë‹¤.
<img src="/assets/img/infrastructure/shared-blockvolume/3.png" alt="" />
ê° compute ì˜ ì„¸ë¶€ ì •ë³´ê°€ ë³´ì—¬ì§‘ë‹ˆë‹¤. ì•„ë˜ ë¦¬ì†ŒìŠ¤ í•­ëª© ì¤‘ì—ì„œ ì—°ê²°ëœ ë¸”ë¡ë³¼ë¥¨ í´ë¦­</li>
</ul>

<p><img src="/assets/img/infrastructure/shared-blockvolume/4.png" alt="" />
ì—°ê²°ëœ ë¸”ë¡ë³¼ë¥¨ì— í˜„ì¬ ì—°ê²°ëœ ë¸”ë¡ë³¼ë¥¨ì´ ì—†ìœ¼ë¯€ë¡œ ì•„ë˜ì™€ ê°™ì´ ë¸”ë¡ë³¼ë¥¨ ì—°ê²° ì´í›„ ì•„ë˜ ì…‹íŒ…ê°’ìœ¼ë¡œ ì—°ê²°í•˜ì‹œ ì´í›„ì— iSCSI ì •ë³´ í™•ì¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‚˜ë¨¸ì§€ script ëª…ë ¹ì–´ëŠ” ì•„ë˜ ë§í¬ í™•ì¸ ë¶€íƒ ë“œë¦½ë‹ˆë‹¤.
<img src="/assets/img/infrastructure/shared-blockvolume/5.png" alt="" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>OCFS2 cluster nodes and open ports 7777 and 3260 in the security list for the virtual cloud network (VCN).


sudo firewall-cmd --zone=public --permanent --add-port=7777/tcp
sudo firewall-cmd --zone=public --permanent --add-port=3260/tcp
sudo firewall-cmd --complete-reload


sudo yum install ocfs2-tools-devel ocfs2-tools -y
sudo o2cb add-cluster ociocfs2


sudo o2cb add-node ociocfs2 hostname --ip 172.X.X.X
sudo o2cb add-node ociocfs2 hostname --ip 172.X.X.X


$ sudo cat /etc/ocfs2/cluster.conf
cluster:
        heartbeat_mode = local
        node_count = 2
        name = ociocfs2
 
node:
        number = 0
        cluster = ociocfs2
        ip_port = 7777
        ip_address = 172.0.0.41
        name = hostname
 
node:
        number = 1
        cluster = ociocfs2
        ip_port = 7777
        ip_address = 172.0.0.42
        name = hostname


$ sudo /sbin/o2cb.init configure
Configuring the O2CB driver.
 
This will configure the on-boot properties of the O2CB driver.
The following questions will determine whether the driver is loaded on
boot. The current values will be shown in brackets ('[]'). Hitting
&lt;ENTER&gt; without typing an answer will keep that current value. Ctrl-C
will abort.
 
Load O2CB driver on boot (y/n) [y]:
Cluster stack backing O2CB [o2cb]:
Cluster to start on boot (Enter "none" to clear) [ocfs2]: ociocfs2
Specify heartbeat dead threshold (&gt;=7) [31]:
Specify network idle timeout in ms (&gt;=5000) [30000]:
Specify network keepalive delay in ms (&gt;=1000) [2000]:
Specify network reconnect delay in ms (&gt;=2000) [2000]:
Writing O2CB configuration: OK
checking debugfs...
Setting cluster stack "o2cb": OK
Registering O2CB cluster "ociocfs2": OK
Setting O2CB cluster timeouts : OK
Starting global heartbeat for cluster "ociocfs2": OK
To verify the settings for the cluster stack, run the /sbin/o2cb.init status command:

$ sudo /sbin/o2cb.init status
Driver for "configfs": Loaded
Filesystem "configfs": Mounted
Stack glue driver: Loaded
Stack plugin "o2cb": Loaded
Driver for "ocfs2_dlmfs": Loaded
Filesystem "ocfs2_dlmfs": Mounted
Checking O2CB cluster "ociocfs2": Online
  Heartbeat dead threshold: 31
  Network idle timeout: 30000
  Network keepalive delay: 2000
  Network reconnect delay: 2000
  Heartbeat mode: Local
Checking O2CB heartbeat: Active
Debug file system at /sys/kernel/debug: mounted
In this example, the cluster is online and is using local heartbeat mode. If no volumes have been configured, the O2CB heartbeat is shown as Not Active rather than Active.

Configure the o2cb and ocfs2 services so that they start at boot time after networking is enabled:

$ sudo systemctl enable o2cb
$ sudo systemctl enable ocfs2
These settings allow the node to mount OCFS2 volumes automatically when the system starts.


1. On each node, enter the following commands to set the recommended values for panic and panic_on_oops:

$ sudo sysctl kernel.panic=30
$ sudo sysctl kernel.panic_on_oops=1
To make the change persist across reboots, add the following entries to the /etc/sysctl.conf file:

# Define panic and panic_on_oops for cluster operation
kernel.panic=30
kernel.panic_on_oops=1


Creating the OCFS2 Volumes
Use the mkfs.ocfs2 command to create an OCFS2 volume on a device.

$ sudo mkfs.ocfs2 -L "ocfs2" /dev/sdb
mkfs.ocfs2 1.8.6
Cluster stack: classic o2cb
Label: ocfs2
Features: sparse extended-slotmap backup-super unwritten inline-data strict-journal-super xattr indexed-dirs refcount discontig-bg
Block size: 4096 (12 bits)
Cluster size: 4096 (12 bits)
Volume size: 12455405158400 (3040870400 clusters) (3040870400 blocks)
Cluster groups: 94274 (tail covers 512 clusters, rest cover 32256 clusters)
Extent allocator size: 780140544 (186 groups)
Journal size: 268435456
Node slots: 16
Creating bitmaps: done
Initializing superblock: done
Writing system files: done
Writing superblock: done
Writing backup superblock: 6 block(s)
Formatting Journals: done
Growing extent allocator: done
Formatting slot map: done
Formatting quota files: done
Writing lost+found: done
mkfs.ocfs2 successful
Mounting the OCFS2 Volumes
As shown in the following example, specify the _netdev option in /etc/fstab to allow the system to mount the OCFS2 volume at boot time after networking is started, and to unmount the file system before networking is stopped.

$ sudo mkdir /ocfs2
$ sudo vi /etc/fstab
#include the below line to mount your ocfs2 after a restart
/dev/sdb /ocfs2 ocfs2     _netdev,defaults   0 0 
Run mount -a to mount the OCFS2 partition based on the fstab entry.

Congratulations! The cluster file system is mounted on /ocfs2 on both the Oracle Linux 7.x node1 and node2 servers.

</code></pre></div></div>

<p>ì˜ìƒì„ ì•„ë˜ ì˜ìƒì€ ì •ìƒì ìœ¼ë¡œ configuration ì„¤ì •ëœ ë¶€ë¶„ì— ëŒ€í•´ì„œ ì˜ìƒì…ë‹ˆë‹¤. 
<!-- Feel free to change the width and height to your desired video size. --></p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/fyqT6GqbZRQ" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<!-- Feel free to change the width and height to your desired video size. -->

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/wbUBIApC8Mo" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

:ET